{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../fuzzy-torch') # or just install the module\n",
    "sys.path.append('../../fuzzy-tools') # or just install the module\n",
    "sys.path.append('../../astro-lightcurves-handler') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from fuzzytools.prints import print_big_bar\n",
    "\n",
    "parser = argparse.ArgumentParser('usage description')\n",
    "parser.add_argument('-method',  type=str, default='spm-mcmc-estw', help='method')\n",
    "parser.add_argument('-gpu',  type=int, default=-1, help='gpu')\n",
    "parser.add_argument('-mc',  type=str, default='parallel_rnn_models', help='model_collections method')\n",
    "parser.add_argument('-batch_size',  type=int, default=512, help='batch_size')\n",
    "parser.add_argument('-load_model',  type=bool, default=False, help='load_model')\n",
    "parser.add_argument('-epochs_max',  type=int, default=1e4, help='epochs_max')\n",
    "parser.add_argument('-save_rootdir',  type=str, default='../save', help='save_rootdir')\n",
    "parser.add_argument('-iid',  type=int, default=0, help='initial id')\n",
    "parser.add_argument('-fid',  type=int, default=5, help='final id')\n",
    "parser.add_argument('-kf',  type=str, default='0', help='kf')\n",
    "parser.add_argument('-rsc',  type=int, default=3, help='random_subcrops')\n",
    "parser.add_argument('-upc',  type=int, default=True, help='precompute')\n",
    "main_args = parser.parse_args(['-gpu', '-1', '-upc', '0'])\n",
    "#main_args = parser.parse_args()\n",
    "print_big_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################################\n",
    "from fuzzytools.files import search_for_filedirs\n",
    "from lchandler import C_ as C_\n",
    "\n",
    "surveys_rootdir = '../../surveys-save/'\n",
    "filedirs = search_for_filedirs(surveys_rootdir, fext=C_.EXT_SPLIT_LIGHTCURVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fuzzytools.files import load_pickle, save_pickle\n",
    "from fuzzytools.files import get_dict_from_filedir\n",
    "\n",
    "filedir = f'../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method={main_args.method}.splcds'\n",
    "filedict = get_dict_from_filedir(filedir)\n",
    "root_folder = filedict['*rootdir*']\n",
    "cfilename = filedict['*cfilename*']\n",
    "survey = filedict['survey']\n",
    "lcdataset = load_pickle(filedir)\n",
    "print(lcdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lcclassifier.models.model_collections import ModelCollections\n",
    "\n",
    "model_collections = ModelCollections(lcdataset)\n",
    "#getattr(model_collections, main_args.mc)()\n",
    "#getattr(model_collections, 'parallel_rnn_models_dt')()\n",
    "#getattr(model_collections, 'parallel_rnn_models_te')()\n",
    "#getattr(model_collections, 'serial_rnn_models_dt')()\n",
    "#getattr(model_collections, 'serial_rnn_models_te')()\n",
    "#getattr(model_collections, 'parallel_tcnn_models_dt')()\n",
    "#getattr(model_collections, 'parallel_tcnn_models_te')()\n",
    "#getattr(model_collections, 'serial_tcnn_models_te')()\n",
    "getattr(model_collections, 'parallel_atcnn_models_te')()\n",
    "#getattr(model_collections, 'serial_atcnn_models_te')()\n",
    "print(model_collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOSS & METRICS\n",
    "from lcclassifier.losses import LCMSEReconstruction, LCXEntropy, LCCompleteLoss\n",
    "from lcclassifier.metrics import LCXEntropyMetric, LCAccuracy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "    'uses_poblation_weights':True,\n",
    "}\n",
    "#pt_loss = LCCompleteLoss('wmse', lcdataset['raw'].band_names)\n",
    "#pt_loss = LCXEntropy('wxentropy', **loss_kwargs)\n",
    "pt_loss = LCCompleteLoss('wmse-xentropy', lcdataset['raw'].band_names, **loss_kwargs)\n",
    "pt_metrics = [\n",
    "    LCXEntropyMetric('xentropy', **loss_kwargs),\n",
    "    LCAccuracy('b-accuracy', balanced=True, **loss_kwargs),\n",
    "    LCAccuracy('accuracy', **loss_kwargs),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if main_args.gpu>=0:\n",
    "    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' # see issue #152\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(main_args.gpu) # CUDA-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "### GRID\n",
    "from lcclassifier.datasets import CustomDataset\n",
    "from lcclassifier.dataloaders import CustomDataLoader\n",
    "\n",
    "for mp_grid in model_collections.pms:\n",
    "    ### DATASETS\n",
    "    dataset_kwargs = mp_grid['dataset_kwargs']\n",
    "    s_train_dataset = CustomDataset(lcdataset, f'{main_args.kf}@train.{main_args.method}', **dataset_kwargs)\n",
    "    s_val_dataset = CustomDataset(lcdataset, f'{main_args.kf}@val.{main_args.method}', **dataset_kwargs)\n",
    "    r_train_dataset = CustomDataset(lcdataset, f'{main_args.kf}@train', **dataset_kwargs)\n",
    "    r_val_dataset = CustomDataset(lcdataset, f'{main_args.kf}@val', **dataset_kwargs)\n",
    "\n",
    "    mp_grid['mdl_kwargs']['curvelength_max'] = s_train_dataset.get_max_len()\n",
    "    mp_grid['dec_mdl_kwargs']['curvelength_max'] = s_train_dataset.get_max_len()\n",
    "    s_train_dataset.transfer_metadata_to(s_val_dataset) # transfer metadata to val/test\n",
    "    s_train_dataset.transfer_metadata_to(r_train_dataset) # transfer metadata to val/test\n",
    "    s_train_dataset.transfer_metadata_to(r_val_dataset) # transfer metadata to val/test\n",
    "\n",
    "    print('s_train_dataset:', s_train_dataset)\n",
    "    print('s_val_dataset:', s_val_dataset)\n",
    "    print('r_train_dataset:', r_train_dataset)\n",
    "    print('r_val_dataset:', r_val_dataset)\n",
    "    \n",
    "    if main_args.upc:\n",
    "        synth_precomputed_samples = 4\n",
    "        real_precomputed_samples = synth_precomputed_samples*32\n",
    "        s_train_dataset.precompute_samples(synth_precomputed_samples)\n",
    "        s_val_dataset.precompute_samples(synth_precomputed_samples)\n",
    "        r_train_dataset.precompute_samples(real_precomputed_samples)\n",
    "        r_val_dataset.precompute_samples(real_precomputed_samples)\n",
    "\n",
    "    ### DATALOADERS\n",
    "    loader_kwargs = {\n",
    "        #'num_workers':2, # bug?\n",
    "        'batch_size':main_args.batch_size,\n",
    "        'random_subcrops':main_args.rsc,\n",
    "    }\n",
    "    s_train_loader = CustomDataLoader(s_train_dataset, shuffle=True, **loader_kwargs)\n",
    "    s_val_loader = CustomDataLoader(s_val_dataset, shuffle=False, **loader_kwargs)\n",
    "    r_train_loader = CustomDataLoader(r_train_dataset, shuffle=True, **loader_kwargs)\n",
    "    r_val_loader = CustomDataLoader(r_val_dataset, shuffle=False, **loader_kwargs)\n",
    "\n",
    "    ### IDS\n",
    "    model_ids = list(range(main_args.iid, main_args.fid+1))\n",
    "    for ki,model_id in enumerate(model_ids): # IDS\n",
    "        ### GET MODEL\n",
    "        mdl_kwargs = mp_grid['mdl_kwargs']\n",
    "        for k_ in ['mdl_kwargs', 'dec_mdl_kwargs']:\n",
    "            mp_grid[k_]['input_dims'] = s_train_loader.dataset.get_output_dims()\n",
    "            mp_grid[k_]['te_features'] = s_train_loader.dataset.get_te_features_dims()\n",
    "            #mp_grid[k_]['curvelength_max'] = s_train_dataset.get_max_len()\n",
    "\n",
    "        model = mdl_kwargs['C'](**mp_grid)\n",
    "\n",
    "        ### OPTIMIZER\n",
    "        import torch.optim as optims\n",
    "        from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "        decay_kwargs = {\n",
    "            'lr':0.95,\n",
    "        }\n",
    "        pt_optimizer_kwargs = {\n",
    "            'opt_kwargs':{\n",
    "                'lr':.5e-3,\n",
    "            },\n",
    "            #'decay_kwargs':decay_kwargs,\n",
    "        }\n",
    "        pt_optimizer = LossOptimizer(model, optims.Adam, **pt_optimizer_kwargs)\n",
    "\n",
    "        ### MONITORS\n",
    "        from fuzzytools.prints import print_bar\n",
    "        from fuzzytorch.handlers import ModelTrainHandler\n",
    "        from fuzzytorch.monitors import LossMonitor\n",
    "        from fuzzytorch import C_\n",
    "        import math\n",
    "\n",
    "        monitor_config = {\n",
    "            'val_epoch_counter_duration':1, # every k epochs check\n",
    "            'earlystop_epoch_duration':20,\n",
    "            #'save_mode':C_.SM_NO_SAVE,\n",
    "            #'save_mode':C_.SM_ALL,\n",
    "            #'save_mode':C_.SM_ONLY_ALL,\n",
    "            #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "            'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "            #'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "        }\n",
    "        pt_loss_monitors = LossMonitor(pt_loss, pt_optimizer, pt_metrics, **monitor_config)\n",
    "\n",
    "        ### TRAIN\n",
    "        mtrain_config = {\n",
    "            'id':model_id,\n",
    "            'epochs_max':1e5,\n",
    "            'save_rootdir':f'../save/training',\n",
    "            'extra_model_name_dict':{\n",
    "                'mode':'pt',\n",
    "                #'ef-be':f'1e{math.log10(s_train_loader.dataset.effective_beta_eps)}',\n",
    "                'ef-be':s_train_loader.dataset.effective_beta_eps,\n",
    "                'rsc':main_args.rsc,\n",
    "            },\n",
    "            'uses_train_eval_loader_methods':True,\n",
    "        }\n",
    "        model_train_handler = ModelTrainHandler(model, pt_loss_monitors, **mtrain_config)\n",
    "        model_train_handler.build_gpu(0 if main_args.gpu>=0 else None)\n",
    "        if ki==0:\n",
    "            print(model_train_handler)\n",
    "        assert 0\n",
    "        model_train_handler.fit_loader(s_train_loader, s_val_loader) # main fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzytorch\n",
    "import fuzzytorch.plots\n",
    "import fuzzytorch.plots.training as ffplots\n",
    "\n",
    "### training plots\n",
    "plot_kwargs = {\n",
    "    'save_rootdir':f'../save/train_plots',\n",
    "}\n",
    "ffplots.plot_loss(model_train_handler, **plot_kwargs)\n",
    "#ffplots.plot_evaluation_loss(train_handler, **plot_kwargs)\n",
    "#ffplots.plot_evaluation_metrics(train_handler, **plot_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import lcclassifier.experiments.images as exp_img\n",
    "\n",
    "### perform the experiments\n",
    "exp_kwargs = {\n",
    "    'save_rootdir':f'../save/experiments',\n",
    "    'm':4,\n",
    "}\n",
    "#exp_img.reconstructions(model_train_handler, s_train_loader, **exp_kwargs)\n",
    "exp_img.reconstructions_m(model_train_handler, s_val_loader, **exp_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import lcclassifier.experiments.performance as exp_perf\n",
    "\n",
    "### perform the experiments\n",
    "exp_kwargs = {\n",
    "    'save_rootdir':f'../save/experiments',\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "#exp_perf.reconstruction_along_days(model_train_handler, s_train_loader, **exp_kwargs)\n",
    "exp_perf.reconstruction_along_days(model_train_handler, s_val_loader, **exp_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import lcclassifier.experiments.performance as exp_perf\n",
    "\n",
    "### perform the experiments\n",
    "exp_kwargs = {\n",
    "    'save_rootdir':f'../save/experiments',\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "#exp_perf.metrics_along_days(model_train_handler, s_val_loader, **exp_kwargs)\n",
    "exp_perf.metrics_along_days(model_train_handler, s_val_loader, **exp_kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
