{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../fuzzy-torch') # or just install the module\n",
    "sys.path.append('../../fuzzy-tools') # or just install the module\n",
    "sys.path.append('../../astro-lightcurves-handler') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzytools.files import search_for_filedirs\n",
    "from lchandler import _C as _C\n",
    "\n",
    "surveys_rootdir = '../../surveys-save/'\n",
    "filedirs = search_for_filedirs(surveys_rootdir, fext=_C.EXT_SPLIT_LIGHTCURVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from fuzzytools.files import load_pickle, save_pickle\n",
    "from fuzzytools.files import get_dict_from_filedir\n",
    "\n",
    "method = 'spm-mcmc-estw'\n",
    "filedir = f'../../surveys-save/survey=alerceZTFv7.1~bands=gr~mode=onlySNe~method={method}.splcds'\n",
    "kf = '3'\n",
    "\n",
    "filedict = get_dict_from_filedir(filedir)\n",
    "root_folder = filedict['_rootdir']\n",
    "cfilename = filedict['_cfilename']\n",
    "survey = filedict['survey']\n",
    "lcdataset = load_pickle(filedir)\n",
    "lcdataset.only_keep_kf(kf) # saves ram\n",
    "print(lcdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcset = lcdataset[f'{kf}@train']\n",
    "values = lcset.get_all_values('obs')\n",
    "print(np.min(values), np.percentile(values, 50), np.max(values))\n",
    "print(np.sort(values)[::-1][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcset = lcdataset[f'{kf}@train.{method}']\n",
    "values = lcset.get_all_values('obs')\n",
    "print(np.min(values), np.percentile(values, 50), np.max(values))\n",
    "print(np.sort(values)[::-1][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from lchandler.plots.distrs import plot_values_distribution\n",
    "\n",
    "kf = 0\n",
    "set_name = f'{kf}@train'\n",
    "lcdataset[set_name].set_diff_parallel('days')\n",
    "plot_values_distribution(lcdataset, set_name, 'd_days')\n",
    "plot_values_distribution(lcdataset, set_name, 'obs')\n",
    "plot_values_distribution(lcdataset, set_name, 'obse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lcclassifier.datasets import CustomDataset\n",
    "\n",
    "dataset_kwargs = {\n",
    "    'max_day':100.,\n",
    "    #attrs':['days','obs', 'obse']\n",
    "    'in_attrs':['obs', 'obse'],\n",
    "    #'attrs':['d_days','obs', 'obse']\n",
    "    'rec_attr':'obs',\n",
    "}\n",
    "repeats = 5\n",
    "device = 'cpu'\n",
    "#lcset_name = f'{kf}@train.{method}'\n",
    "lcset_name = f'{kf}@train'\n",
    "s_train_dataset_da = CustomDataset(lcset_name, copy(lcdataset[lcset_name]), device,\n",
    "    balanced_repeats=repeats,\n",
    "    precomputed_copies=2, # 1 8 16\n",
    "    uses_daugm=True,\n",
    "    uses_dynamic_balance=True,\n",
    "    ds_mode={'random':.75, 'left':.0, 'none':.25,},\n",
    "    **dataset_kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "s_train_dataset_da.calcule_precomputed(verbose=1, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lcclassifier.datasets import CustomDataset\n",
    "\n",
    "\n",
    "lcset_name = f'{main_args.kf}@train.{main_args.method}'\n",
    "s_train_dataset_da = CustomDataset(lcset_name, copy(lcdataset[lcset_name]), device,\n",
    "    balanced_repeats=repeats,\n",
    "    precomputed_copies=8, # 1 8 16\n",
    "    uses_daugm=True,\n",
    "    uses_dynamic_balance=True,\n",
    "    ds_mode={'random':.75, 'left':.0, 'none':.25,},\n",
    "    **dataset_kwargs,\n",
    "    )\n",
    "\n",
    "device = 'cpu' # cpu\n",
    "train_dataset = CustomDataset(f'{kf}@train.{method}', copy(lcdataset[f'{kf}@train.{method}']), device, **dataset_kwargs)\n",
    "val_dataset = CustomDataset(f'{kf}@val', copy(lcdataset[f'{kf}@val']), device, **dataset_kwargs)\n",
    "train_dataset.transfer_scalers_to(val_dataset) # transfer metadata to val/test\n",
    "print('train_dataset:', train_dataset)\n",
    "print('val_dataset:', val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fuzzytorch.utils import print_tdict\n",
    "import cProfile\n",
    "\n",
    "p = cProfile.Profile(); p.enable()\n",
    "tdict = train_dataset.get_item(train_dataset.get_lcobj_names()[0])\n",
    "print_tdict(tdict)\n",
    "p.disable(); p.dump_stats('prof.prof')\n",
    "print(tdict['target']['balanced_w'])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from lchandler.plots.lc import plot_lightcurve\n",
    "from lchandler import C_ as C_\n",
    "%matplotlib inline\n",
    "\n",
    "dataset = train_dataset\n",
    "lcobj_name = dataset.get_random_stratified_lcobj_names()[0]\n",
    "\n",
    "\n",
    "tdict, lcobj = dataset.get_item(lcobj_name, uses_len_clip=False, uses_daugm=False, return_lcobjs=True)\n",
    "print(lcobj)\n",
    "\n",
    "\n",
    "minput = tdict['input']\n",
    "target = tdict['target']\n",
    "\n",
    "figsize = (10,13)\n",
    "fig, axs = plt.subplots(5+1, 1, figsize=figsize)\n",
    "\n",
    "ax = axs[0]\n",
    "for kb,b in enumerate(dataset.band_names):\n",
    "    plot_lightcurve(ax, lcobj, b, label=f'{b} obs', max_day=dataset.max_day)\n",
    "ax.set_ylabel('observation')\n",
    "\n",
    "b = 'r'\n",
    "len_lcobj = minput[f'onehot.{b}'].sum()\n",
    "ax = axs[1]\n",
    "time = minput[f'rtime.{b}'][...,0]\n",
    "for ka,in_attr in enumerate(dataset.in_attrs):\n",
    "    ax.plot(time[:len_lcobj], minput[f'x.{b}'][:len_lcobj,ka], '-o', label=f'{C_.SHORT_NAME_DICT[in_attr]} (norm)')\n",
    "ax.set_ylabel(f'x.{b}')\n",
    "\n",
    "ax = axs[2]\n",
    "ax.plot(time[:len_lcobj], minput[f'onehot.{b}'][:len_lcobj], 'o')\n",
    "ax.set_ylabel(f'onehot.{b}')\n",
    "\n",
    "ax = axs[3]\n",
    "ax.plot(time[:len_lcobj], minput[f'rtime.{b}'][:len_lcobj], '-o')\n",
    "ax.set_ylabel(f'time.{b}')\n",
    "\n",
    "ax = axs[4]\n",
    "ax.plot(time[:len_lcobj], minput[f'dtime.{b}'][:len_lcobj], '-o')\n",
    "ax.set_ylabel(f'dtime.{b}')\n",
    "\n",
    "ax = axs[5]\n",
    "ax.plot(time[:len_lcobj], target[f'rec_x.{b}'][:len_lcobj], '-o')\n",
    "ax.set_ylabel(f'rec_x.{b}')\n",
    "\n",
    "class_name = dataset.class_names[target['y']]\n",
    "title = ''\n",
    "title += f'training light curve sample & model inputs & onehot & temporal encoding \\n'\n",
    "title += f'survey: {dataset.lcset.survey} - set: {dataset.lcset_name}'\n",
    "title += f' - class: {class_name} - max_day: {dataset.max_day:.2f} - max_len: {dataset.max_len}'\n",
    "#title += f' - training: {dataset.training}'\n",
    "for ax in axs:\n",
    "    #ax.legend(prop={'size':14})\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(alpha=0.5)\n",
    "axs[0].set_title(title)\n",
    "axs[-1].set_xlabel('days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lcclassifier.dataloaders import CustomDataLoader\n",
    "from fuzzytorch.utils import print_tdict\n",
    "\n",
    "loader_kwargs = {\n",
    "    'batch_size':2,\n",
    "}\n",
    "random_subcrops = 3\n",
    "s_train_loader = CustomDataLoader(train_dataset, shuffle=False, **loader_kwargs)\n",
    "s_train_loader.eval()\n",
    "dataset.set_max_day(40)\n",
    "\n",
    "for k,tdict in enumerate(s_train_loader):\n",
    "    target = tdict['target']\n",
    "    print_tdict(tdict)\n",
    "    print(tdict['input']['rtime.*'][0,:,0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lcclassifier.dataloaders import CustomDataLoader\n",
    "from fuzzytorch.utils import print_tdict\n",
    "\n",
    "loader_kwargs = {\n",
    "    'batch_size':1,\n",
    "    #'num_workers':1, # bug?\n",
    "}\n",
    "random_subcrops = 3\n",
    "s_train_loader = CustomDataLoader(train_dataset, shuffle=True, random_subcrops=random_subcrops, **loader_kwargs)\n",
    "s_train_loader.train()\n",
    "\n",
    "for k,tdict in enumerate(s_train_loader):\n",
    "    model_input = tdict['input']\n",
    "    target = tdict['target']\n",
    "    print_tdict(tdict)\n",
    "    for idx in range(len(model_input['x'])):\n",
    "        print(model_input['x'][idx,:,0])\n",
    "        print(model_input['onehot'][idx].sum(-1))\n",
    "    assert 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
