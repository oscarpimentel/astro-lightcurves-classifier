{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../fuzzy-torch') # or just install the module\n",
    "sys.path.append('../../fuzzy-tools') # or just install the module\n",
    "sys.path.append('../../astro-lightcurves-handler') # or just install the module\n",
    "sys.path.append('../../sne-lightcurves-synthetic') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "found filedirs: (../../surveys-save/)\n",
      "(0) - ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=mcmc.splcds - 125.451[mbs]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "filedirs after searching with filters: (../../surveys-save/)\n",
      "(0) - ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=mcmc.splcds - 125.451[mbs]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from fuzzytools.files import search_for_filedirs\n",
    "from lchandler import C_ as C_\n",
    "\n",
    "surveys_rootdir = '../../surveys-save/'\n",
    "filedirs = search_for_filedirs(surveys_rootdir, fext=C_.EXT_SPLIT_LIGHTCURVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m> loading: ../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=mcmc.splcds\u001b[0m\n",
      "dict_keys(['data', 'survey', 'description', 'band_names', 'class_names', 'obs_is_flux'])\n",
      "dict_keys(['days', 'obs', 'obse', 'y', 'synthetic'])\n",
      "LCDataset:\n",
      "[outliers - samples 10]\n",
      "(*) obs_samples: 541 - min_len: 14 - max_dur: 408.0[days] - dur(p50): 133.8[days] - cadence(p50): 1.0[days]\n",
      "(g) obs_samples: 260 - min_len: 6 - max_dur: 408.0[days] - dur(p50): 133.7[days] - cadence(p50): 3.0[days]\n",
      "(r) obs_samples: 281 - min_len: 8 - max_dur: 376.0[days] - dur(p50): 128.7[days] - cadence(p50): 3.0[days]\n",
      "   |█▌      | SLSN - 2/10 (20.00%)\n",
      "   |▊       | SNIa - 1/10 (10.00%)\n",
      "   |█▌      | SNIbc - 2/10 (20.00%)\n",
      "   |████    | allSNII - 5/10 (50.00%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[faint - samples 44]\n",
      "(*) obs_samples: 990 - min_len: 7 - max_dur: 298.1[days] - dur(p50): 40.0[days] - cadence(p50): 1.0[days]\n",
      "(g) obs_samples: 409 - min_len: 0 - max_dur: 221.7[days] - dur(p50): 26.9[days] - cadence(p50): 2.9[days]\n",
      "(r) obs_samples: 581 - min_len: 4 - max_dur: 298.1[days] - dur(p50): 37.5[days] - cadence(p50): 3.0[days]\n",
      "   |█▎      | SLSN - 7/44 (15.91%)\n",
      "   |███▊    | SNIa - 21/44 (47.73%)\n",
      "   |▌       | SNIbc - 3/44 (6.82%)\n",
      "   |██▎     | allSNII - 13/44 (29.55%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[raw - samples 1,944]\n",
      "(*) obs_samples: 53,443 - min_len: 6 - max_dur: 538.8[days] - dur(p50): 53.0[days] - cadence(p50): 1.0[days]\n",
      "(g) obs_samples: 23,607 - min_len: 0 - max_dur: 538.8[days] - dur(p50): 39.0[days] - cadence(p50): 3.0[days]\n",
      "(r) obs_samples: 29,836 - min_len: 0 - max_dur: 538.8[days] - dur(p50): 51.0[days] - cadence(p50): 3.0[days]\n",
      "   |        | SLSN - 22/1,944 (1.13%)\n",
      "   |██████  | SNIa - 1,479/1,944 (76.08%)\n",
      "   |▍       | SNIbc - 95/1,944 (4.89%)\n",
      "   |█▍      | allSNII - 348/1,944 (17.90%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[train - samples 1,242]\n",
      "(*) obs_samples: 34,028 - min_len: 4 - max_dur: 444.7[days] - dur(p50): 52.0[days] - cadence(p50): 1.0[days]\n",
      "(g) obs_samples: 14,975 - min_len: 0 - max_dur: 443.9[days] - dur(p50): 38.1[days] - cadence(p50): 3.0[days]\n",
      "(r) obs_samples: 19,053 - min_len: 0 - max_dur: 443.9[days] - dur(p50): 49.9[days] - cadence(p50): 3.0[days]\n",
      "   |        | SLSN - 14/1,242 (1.13%)\n",
      "   |██████  | SNIa - 946/1,242 (76.17%)\n",
      "   |▍       | SNIbc - 60/1,242 (4.83%)\n",
      "   |█▍      | allSNII - 222/1,242 (17.87%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[val - samples 309]\n",
      "(*) obs_samples: 8,603 - min_len: 6 - max_dur: 538.8[days] - dur(p50): 55.0[days] - cadence(p50): 1.1[days]\n",
      "(g) obs_samples: 3,820 - min_len: 0 - max_dur: 538.8[days] - dur(p50): 39.0[days] - cadence(p50): 3.0[days]\n",
      "(r) obs_samples: 4,783 - min_len: 0 - max_dur: 538.8[days] - dur(p50): 52.8[days] - cadence(p50): 3.0[days]\n",
      "   |        | SLSN - 3/309 (0.97%)\n",
      "   |██████  | SNIa - 236/309 (76.38%)\n",
      "   |▍       | SNIbc - 15/309 (4.85%)\n",
      "   |█▍      | allSNII - 55/309 (17.80%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[test - samples 393]\n",
      "(*) obs_samples: 10,593 - min_len: 7 - max_dur: 344.1[days] - dur(p50): 54.0[days] - cadence(p50): 1.0[days]\n",
      "(g) obs_samples: 4,712 - min_len: 0 - max_dur: 324.1[days] - dur(p50): 40.9[days] - cadence(p50): 3.0[days]\n",
      "(r) obs_samples: 5,881 - min_len: 0 - max_dur: 342.0[days] - dur(p50): 52.8[days] - cadence(p50): 3.0[days]\n",
      "   |        | SLSN - 5/393 (1.27%)\n",
      "   |██████  | SNIa - 297/393 (75.57%)\n",
      "   |▍       | SNIbc - 20/393 (5.09%)\n",
      "   |█▍      | allSNII - 71/393 (18.07%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[train+val - samples 1,551]\n",
      "(*) obs_samples: 42,631 - min_len: 4 - max_dur: 538.8[days] - dur(p50): 52.9[days] - cadence(p50): 1.0[days]\n",
      "(g) obs_samples: 18,795 - min_len: 0 - max_dur: 538.8[days] - dur(p50): 38.9[days] - cadence(p50): 3.0[days]\n",
      "(r) obs_samples: 23,836 - min_len: 0 - max_dur: 538.8[days] - dur(p50): 50.0[days] - cadence(p50): 3.0[days]\n",
      "   |        | SLSN - 17/1,551 (1.10%)\n",
      "   |██████  | SNIa - 1,182/1,551 (76.21%)\n",
      "   |▍       | SNIbc - 75/1,551 (4.84%)\n",
      "   |█▍      | allSNII - 277/1,551 (17.86%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[train+val.mcmc - samples 100,175]\n",
      "(*) obs_samples: 2,891,274 - min_len: 4 - max_dur: 573.2[days] - dur(p50): 62.2[days] - cadence(p50): 2.3[days]\n",
      "(g) obs_samples: 1,268,004 - min_len: 0 - max_dur: 570.1[days] - dur(p50): 45.2[days] - cadence(p50): 3.1[days]\n",
      "(r) obs_samples: 1,623,270 - min_len: 0 - max_dur: 573.2[days] - dur(p50): 59.8[days] - cadence(p50): 3.2[days]\n",
      "   |        | SLSN - 1,105/100,175 (1.10%)\n",
      "   |██████  | SNIa - 76,318/100,175 (76.18%)\n",
      "   |▍       | SNIbc - 4,811/100,175 (4.80%)\n",
      "   |█▍      | allSNII - 17,941/100,175 (17.91%)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from fuzzytools.files import load_pickle, save_pickle\n",
    "from fuzzytools.files import get_dict_from_filedir\n",
    "from lchandler import C_ as C_\n",
    "\n",
    "def load_lcdataset(filename):\n",
    "    assert filename.split('.')[-1]==C_.EXT_SPLIT_LIGHTCURVE\n",
    "    return load_pickle(filename)\n",
    "\n",
    "filedir = '../../surveys-save/alerceZTFv7.1/survey=alerceZTFv7.1°bands=gr°mode=onlySNe°method=mcmc.splcds'\n",
    "\n",
    "filedict = get_dict_from_filedir(filedir)\n",
    "root_folder = filedict['*rootdir*']\n",
    "cfilename = filedict['*cfilename*']\n",
    "survey = filedict['survey']\n",
    "lcdataset = load_lcdataset(filedir)\n",
    "print(lcdataset['raw'].keys())\n",
    "print(lcdataset['raw'].get_random_lcobj(False).keys())\n",
    "print(lcdataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - mdl_kwargs: {'C': <class 'lcclassifier.models.model_baselines.ParallelAttnTCNClassifier'>, 'tcn_embd_dims': 32, 'tcn_layers': 2, 'dropout': {'p': 0.1}, 'band_names': ['g', 'r'], 'output_dims': 4}\n",
      "(0) - dataset_kwargs: {'attrs': ['log_obs', 'log_obse'], 'max_day': 70.0, 'te_features': 8}\n",
      "(0) - dec_mdl_kwargs: {'C': <class 'lcclassifier.models.rnn.decoders.RNNDecoderS'>, 'rnn_cell_name': 'GRU', 'rnn_layers': 1, 'dropout': {'p': 0.1}, 'band_names': ['g', 'r'], 'output_dims': 4}\n",
      "(0) - class_mdl_kwargs: {'C': <class 'lcclassifier.models.classifiers.SimpleClassifier'>, 'embd_layers': 1, 'dropout': {'p': 0.1}, 'band_names': ['g', 'r'], 'output_dims': 4}\n",
      "---\n",
      "(1) - mdl_kwargs: {'C': <class 'lcclassifier.models.model_baselines.ParallelAttnTCNClassifier'>, 'tcn_embd_dims': 64, 'tcn_layers': 2, 'dropout': {'p': 0.1}, 'band_names': ['g', 'r'], 'output_dims': 4}\n",
      "(1) - dataset_kwargs: {'attrs': ['log_obs', 'log_obse'], 'max_day': 70.0, 'te_features': 8}\n",
      "(1) - dec_mdl_kwargs: {'C': <class 'lcclassifier.models.rnn.decoders.RNNDecoderS'>, 'rnn_cell_name': 'GRU', 'rnn_layers': 1, 'dropout': {'p': 0.1}, 'band_names': ['g', 'r'], 'output_dims': 4}\n",
      "(1) - class_mdl_kwargs: {'C': <class 'lcclassifier.models.classifiers.SimpleClassifier'>, 'embd_layers': 1, 'dropout': {'p': 0.1}, 'band_names': ['g', 'r'], 'output_dims': 4}\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lcclassifier.models.model_collections import ModelCollections\n",
    "\n",
    "model_collections = ModelCollections(lcdataset)\n",
    "#getattr(model_collections, 'parallel_rnn_models_dt')()\n",
    "#getattr(model_collections, 'parallel_rnn_models_te')()\n",
    "#getattr(model_collections, 'serial_rnn_models_dt')()\n",
    "#getattr(model_collections, 'serial_rnn_models_te')()\n",
    "#getattr(model_collections, 'parallel_tcn_models_dt')()\n",
    "#getattr(model_collections, 'parallel_tcn_models_te')()\n",
    "#getattr(model_collections, 'serial_tcn_models_dt')()\n",
    "#getattr(model_collections, 'serial_tcn_models_te')()\n",
    "getattr(model_collections, 'parallel_atcn_models_te')()\n",
    "#getattr(model_collections, 'serial_atcn_models_te')()\n",
    "print(model_collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "x_projection: Linear(input_dims=5, output_dims=32, activation=linear, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(192[p])\n",
      "te_film: FILM(mod_input_dims=2, mod_output_dims=32, in_dropout=0.0, out_dropout=0.0, bias=True)(192[p])\n",
      "ml_cnn: ModuleDict(\n",
      "  (g): MLConv1D(\n",
      "    (0) - Conv1DLinear(input_dims=32, input_space=[100], output_dims=32, output_space=[100], spatial_field=[6], cnn_kwargs={'kernel_size': [5], 'stride': [1], 'dilation': [1]}, pool_kwargs={'kernel_size': [2], 'stride': [1], 'dilation': [1]}, padding_mode=causal, activation=relu, in_dropout=0.1, out_dropout=0.0, bias=True)(5,152[p])\n",
      "    (1) - Conv1DLinear(input_dims=32, input_space=[100], output_dims=32, output_space=[100], spatial_field=[6], cnn_kwargs={'kernel_size': [5], 'stride': [1], 'dilation': [1]}, pool_kwargs={'kernel_size': [2], 'stride': [1], 'dilation': [1]}, padding_mode=causal, activation=linear, in_dropout=0.1, out_dropout=0.0, bias=True)(5,152[p])\n",
      "  )(10,304[p])\n",
      "  (r): MLConv1D(\n",
      "    (0) - Conv1DLinear(input_dims=32, input_space=[100], output_dims=32, output_space=[100], spatial_field=[6], cnn_kwargs={'kernel_size': [5], 'stride': [1], 'dilation': [1]}, pool_kwargs={'kernel_size': [2], 'stride': [1], 'dilation': [1]}, padding_mode=causal, activation=relu, in_dropout=0.1, out_dropout=0.0, bias=True)(5,152[p])\n",
      "    (1) - Conv1DLinear(input_dims=32, input_space=[100], output_dims=32, output_space=[100], spatial_field=[6], cnn_kwargs={'kernel_size': [5], 'stride': [1], 'dilation': [1]}, pool_kwargs={'kernel_size': [2], 'stride': [1], 'dilation': [1]}, padding_mode=causal, activation=linear, in_dropout=0.1, out_dropout=0.0, bias=True)(5,152[p])\n",
      "  )(10,304[p])\n",
      ")\n",
      "ml_attn: MLSelfAttn(\n",
      "  (0) - SelfAttn(input_dims=32, output_dims=32, max_curve_length=100, num_heads=2, activation=linear, in_dropout=0.1, out_dropout=0.0, attn_dropout=0.0, mlp_dropout=0.0, bias=True)(8,544[p])\n",
      ")(8,544[p])\n",
      "attn_te_film: FILM(mod_input_dims=2, mod_output_dims=32, in_dropout=0.0, out_dropout=0.0, bias=True)(192[p])\n",
      "x_projection: Linear(input_dims=34, output_dims=32, activation=linear, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(1,120[p])\n",
      "te_film: FILM(mod_input_dims=2, mod_output_dims=32, in_dropout=0.0, out_dropout=0.0, bias=True)(192[p])\n",
      "ml_rnn: MLRNN(\n",
      "  (0) - GRU(input_dims=32, output_dims=32, max_curve_length=100, in_dropout=0.1, out_dropout=0.0, bias=True, bidirectional=False)(6,336[p])\n",
      ")(6,336[p])\n",
      "dz_projection: MLP(\n",
      "  (0) - Linear(input_dims=32, output_dims=32, activation=linear, in_dropout=0.1, out_dropout=0.0, bias=True, split_out=1)(1,056[p])\n",
      "  (1) - Linear(input_dims=32, output_dims=1, activation=linear, in_dropout=0.1, out_dropout=0.0, bias=True, split_out=1)(33[p])\n",
      ")(1,089[p])\n",
      "classifier_mlp: MLP(\n",
      "  (0) - Linear(input_dims=32, output_dims=32, activation=relu, in_dropout=0.1, out_dropout=0.0, bias=True, split_out=1)(1,056[p])\n",
      "  (1) - Linear(input_dims=32, output_dims=4, activation=linear, in_dropout=0.1, out_dropout=0.0, bias=True, split_out=1)(132[p])\n",
      ")(1,188[p])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "p = model_collections.pms[0]\n",
    "p['mdl_kwargs'].update({'input_dims':3})\n",
    "p['dec_mdl_kwargs'].update({'input_dims':3})\n",
    "p['mdl_kwargs'].update({'te_features':2})\n",
    "p['dec_mdl_kwargs'].update({'te_features':2})\n",
    "p['mdl_kwargs'].update({'curvelength_max':100})\n",
    "p['dec_mdl_kwargs'].update({'curvelength_max':100})\n",
    "m = p['mdl_kwargs']['C'](**p)\n",
    "#print(m)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - cpu test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOSS & METRICS\n",
    "from lcclassifier.losses import LCMSEReconstruction, LCXEntropy, LCCompleteLoss\n",
    "from lcclassifier.metrics import LCXEntropyMetric, LCAccuracy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "#pre_loss = LCCompleteLoss('wmse', lcdataset['raw'].band_names)\n",
    "#pre_loss = LCCrossEntropy('wxentropy', **loss_kwargs)\n",
    "pre_loss = LCCompleteLoss('wmse-wxentropy', lcdataset['raw'].band_names, **loss_kwargs)\n",
    "\n",
    "pre_metrics = [\n",
    "    LCXEntropyMetric('wxentropy', **loss_kwargs),\n",
    "    LCAccuracy('b-accuracy', balanced=True, **loss_kwargs),\n",
    "    LCAccuracy('accuracy', **loss_kwargs),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from fuzzytools.prints import print_big_bar\n",
    "\n",
    "parser = argparse.ArgumentParser('usage description')\n",
    "parser.add_argument('-gpu',  type=int, default=-1, help='gpu_index')\n",
    "parser.add_argument('-mc',  type=str, default='parallel_rnn_models', help='model_collections method')\n",
    "parser.add_argument('-email',  type=bool, default=False, help='send_email')\n",
    "parser.add_argument('-batch_size',  type=int, default=512, help='batch_size')\n",
    "parser.add_argument('-load_model',  type=bool, default=False, help='load_model')\n",
    "parser.add_argument('-epochs_max',  type=int, default=int(1e4), help='epochs_max')\n",
    "parser.add_argument('-save_rootdir',  type=str, default='SAVE_TESIS1', help='save_rootdir')\n",
    "parser.add_argument('-iid',  type=int, default=1, help='initial id')\n",
    "parser.add_argument('-fid',  type=int, default=5, help='final id')\n",
    "main_args = parser.parse_args('')\n",
    "print_big_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if main_args.gpu>=0:\n",
    "    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' # see issue #152\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(main_args.gpu) # CUDA-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "s_train_dataset: CustomDataset(lcset_len=100,175, max_day=70.00, max_len=119, te_periods=[140.0, 70.0, 35.0, 17.5], attrs=['log_obs', 'log_obse'], norm_bdict={'g': StandardScaler(copy=True, with_mean=True, with_std=True), 'r': StandardScaler(copy=True, with_mean=True, with_std=True)}, poblation_weights={'SLSN': 0.664856146379499, 'SNIa': 0.0695900541420609, 'SNIbc': 0.18212670309382795, 'allSNII': 0.0834270963846122})\n",
      "r_train_dataset: CustomDataset(lcset_len=1,242, max_day=70.00, max_len=119, te_periods=[140.0, 70.0, 35.0, 17.5], attrs=['log_obs', 'log_obse'], norm_bdict={'g': StandardScaler(copy=True, with_mean=True, with_std=True), 'r': StandardScaler(copy=True, with_mean=True, with_std=True)}, poblation_weights={'SLSN': 0.664856146379499, 'SNIa': 0.0695900541420609, 'SNIbc': 0.18212670309382795, 'allSNII': 0.0834270963846122})\n",
      "r_val_dataset: CustomDataset(lcset_len=309, max_day=70.00, max_len=119, te_periods=[140.0, 70.0, 35.0, 17.5], attrs=['log_obs', 'log_obse'], norm_bdict={'g': StandardScaler(copy=True, with_mean=True, with_std=True), 'r': StandardScaler(copy=True, with_mean=True, with_std=True)}, poblation_weights={'SLSN': 0.664856146379499, 'SNIa': 0.0695900541420609, 'SNIbc': 0.18212670309382795, 'allSNII': 0.0834270963846122})\n",
      "100%|██████████| 100175/100175 [04:11, 398.89it/s, train+val.mcmc ['ZTF19abqjypm.64']]\n",
      "100%|██████████| 1242/1242 [01:02, 19.78it/s, train ['ZTF19aamggmk']]\n",
      "100%|██████████| 309/309 [00:16, 19.19it/s, val ['ZTF18absldfl']]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-91896004d652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m### IDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mmodel_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mki\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# IDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### GRID\n",
    "from lcclassifier.datasets import CustomDataset\n",
    "from lcclassifier.dataloaders import CustomDataLoader\n",
    "\n",
    "for mp_grid in model_collections.pms:\n",
    "    ### DATASETS\n",
    "    dataset_kwargs = mp_grid['dataset_kwargs']\n",
    "\n",
    "    s_train_dataset = CustomDataset(lcdataset, 'train+val.mcmc', **dataset_kwargs)\n",
    "    r_train_dataset = CustomDataset(lcdataset, 'train', **dataset_kwargs)\n",
    "    r_val_dataset = CustomDataset(lcdataset, 'val', **dataset_kwargs)\n",
    "\n",
    "    s_train_dataset.transfer_to(r_train_dataset) # transfer information to val/test\n",
    "    s_train_dataset.transfer_to(r_val_dataset) # transfer information to val/test\n",
    "    mp_grid['mdl_kwargs']['curvelength_max'] = s_train_dataset.get_max_len()\n",
    "    mp_grid['dec_mdl_kwargs']['curvelength_max'] = s_train_dataset.get_max_len()\n",
    "\n",
    "    print('s_train_dataset:', s_train_dataset)\n",
    "    print('r_train_dataset:', r_train_dataset)\n",
    "    print('r_val_dataset:', r_val_dataset)\n",
    "\n",
    "    s_train_dataset.generate_daugm_samples(1)\n",
    "    r_train_dataset.generate_daugm_samples(50)\n",
    "    r_val_dataset.generate_daugm_samples(50)\n",
    "\n",
    "    ### DATALOADERS\n",
    "    loader_kwargs = {\n",
    "        'batch_size':512,\n",
    "        #'num_workers':2, # bug?\n",
    "    }\n",
    "    s_train_loader = CustomDataLoader(s_train_dataset, shuffle=True, **loader_kwargs)\n",
    "    r_train_loader = CustomDataLoader(r_train_dataset, shuffle=True, **loader_kwargs)\n",
    "    r_val_loader = CustomDataLoader(r_val_dataset, random_subcrops=0, **loader_kwargs)\n",
    "\n",
    "    ### IDS\n",
    "    assert 0\n",
    "    model_ids = range(0, 5)\n",
    "    for ki,model_id in enumerate(model_ids): # IDS\n",
    "        ### GET MODEL\n",
    "        mdl_kwargs = mp_grid['mdl_kwargs']\n",
    "        for k_ in ['mdl_kwargs', 'dec_mdl_kwargs']:\n",
    "            mp_grid[k_]['input_dims'] = s_train_loader.dataset.get_output_dims()\n",
    "            mp_grid[k_]['te_features'] = s_train_loader.dataset.get_te_features_dims()\n",
    "            mp_grid[k_]['curvelength_max'] = s_train_dataset.get_max_len()\n",
    "\n",
    "        model = mdl_kwargs['C'](**mp_grid)\n",
    "\n",
    "        ### OPTIMIZER\n",
    "        import torch.optim as optims\n",
    "        from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "        pre_optimizer_kwargs = {\n",
    "            'opt_kwargs':{\n",
    "                'lr':1e-3,\n",
    "            },\n",
    "            'decay_kwargs':{\n",
    "                'lr':0.9,\n",
    "            }\n",
    "        }\n",
    "        pre_optimizer = LossOptimizer(model, optims.Adam, **pre_optimizer_kwargs)\n",
    "\n",
    "        ### MONITORS\n",
    "        from fuzzytools.prints import print_bar\n",
    "        from fuzzytorch.handlers import ModelTrainHandler\n",
    "        from fuzzytorch.monitors import LossMonitor\n",
    "        from fuzzytorch import C_\n",
    "        import math\n",
    "\n",
    "        monitor_config = {\n",
    "            'val_epoch_counter_duration':1, # every k epochs check\n",
    "            'earlystop_epoch_duration':25,\n",
    "            #'save_mode':C_.SM_NO_SAVE,\n",
    "            #'save_mode':C_.SM_ALL,\n",
    "            #'save_mode':C_.SM_ONLY_ALL,\n",
    "            'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "            #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "            #'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "        }\n",
    "        pre_loss_monitors = LossMonitor(pre_loss, pre_optimizer, pre_metrics, **monitor_config)\n",
    "\n",
    "        ### TRAIN\n",
    "        mtrain_config = {\n",
    "            'id':model_id,\n",
    "            'epochs_max':1e5,\n",
    "            'save_rootdir':f'../save/training',\n",
    "            'extra_model_name_dict':{\n",
    "                #'ef-be':f'1e{math.log10(s_train_loader.dataset.effective_beta_eps)}',\n",
    "                'ef-be':s_train_loader.dataset.effective_beta_eps,\n",
    "            },\n",
    "            'uses_train_eval_loader_methods':True,\n",
    "        }\n",
    "        model_train_handler = ModelTrainHandler(model, pre_loss_monitors, **mtrain_config)\n",
    "        model_train_handler.build_gpu(0 if main_args.gpu>=0 else None)\n",
    "        if ki==0:\n",
    "            print(model_train_handler)\n",
    "        model_train_handler.fit_loader(s_train_loader, r_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "x_projection: ModuleDict(\n",
      "  (g): Linear(input_dims=2, output_dims=32, activation=linear, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(96[p])\n",
      "  (r): Linear(input_dims=2, output_dims=32, activation=linear, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(96[p])\n",
      ")\n",
      "te_film: FILM(mod_input_dims=8, mod_output_dims=32, in_dropout=0.0, out_dropout=0.0, bias=True)(576[p])\n",
      "ml_cnn: ModuleDict(\n",
      "  (g): MLConv1D(\n",
      "    (0) - Conv1DLinear(input_dims=32, input_space=[119], output_dims=32, output_space=[119], spatial_field=[6], cnn_kwargs={'kernel_size': [5], 'stride': [1], 'dilation': [1]}, pool_kwargs={'kernel_size': [2], 'stride': [1], 'dilation': [1]}, padding_mode=causal, activation=relu, in_dropout=0.1, out_dropout=0.0, bias=True)(5,152[p])\n",
      "    (1) - Conv1DLinear(input_dims=32, input_space=[119], output_dims=32, output_space=[119], spatial_field=[6], cnn_kwargs={'kernel_size': [5], 'stride': [1], 'dilation': [1]}, pool_kwargs={'kernel_size': [2], 'stride': [1], 'dilation': [1]}, padding_mode=causal, activation=linear, in_dropout=0.1, out_dropout=0.0, bias=True)(5,152[p])\n",
      "  )(10,304[p])\n",
      "  (r): MLConv1D(\n",
      "    (0) - Conv1DLinear(input_dims=32, input_space=[119], output_dims=32, output_space=[119], spatial_field=[6], cnn_kwargs={'kernel_size': [5], 'stride': [1], 'dilation': [1]}, pool_kwargs={'kernel_size': [2], 'stride': [1], 'dilation': [1]}, padding_mode=causal, activation=relu, in_dropout=0.1, out_dropout=0.0, bias=True)(5,152[p])\n",
      "    (1) - Conv1DLinear(input_dims=32, input_space=[119], output_dims=32, output_space=[119], spatial_field=[6], cnn_kwargs={'kernel_size': [5], 'stride': [1], 'dilation': [1]}, pool_kwargs={'kernel_size': [2], 'stride': [1], 'dilation': [1]}, padding_mode=causal, activation=linear, in_dropout=0.1, out_dropout=0.0, bias=True)(5,152[p])\n",
      "  )(10,304[p])\n",
      ")\n",
      "ml_attn: MLSelfAttn(\n",
      "  (0) - SelfAttn(input_dims=32, output_dims=32, max_curve_length=119, num_heads=2, activation=linear, in_dropout=0.1, out_dropout=0.0, attn_dropout=0.0, mlp_dropout=0.0, bias=True)(8,544[p])\n",
      ")(8,544[p])\n",
      "attn_te_film: FILM(mod_input_dims=8, mod_output_dims=32, in_dropout=0.0, out_dropout=0.0, bias=True)(576[p])\n",
      "x_projection: Linear(input_dims=34, output_dims=32, activation=linear, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(1,120[p])\n",
      "te_film: FILM(mod_input_dims=8, mod_output_dims=32, in_dropout=0.0, out_dropout=0.0, bias=True)(576[p])\n",
      "ml_rnn: MLRNN(\n",
      "  (0) - GRU(input_dims=32, output_dims=32, max_curve_length=119, in_dropout=0.1, out_dropout=0.0, bias=True, bidirectional=False)(6,336[p])\n",
      ")(6,336[p])\n",
      "dz_projection: MLP(\n",
      "  (0) - Linear(input_dims=32, output_dims=32, activation=linear, in_dropout=0.1, out_dropout=0.0, bias=True, split_out=1)(1,056[p])\n",
      "  (1) - Linear(input_dims=32, output_dims=1, activation=linear, in_dropout=0.1, out_dropout=0.0, bias=True, split_out=1)(33[p])\n",
      ")(1,089[p])\n",
      "classifier_mlp: MLP(\n",
      "  (0) - Linear(input_dims=32, output_dims=32, activation=relu, in_dropout=0.1, out_dropout=0.0, bias=True, split_out=1)(1,056[p])\n",
      "  (1) - Linear(input_dims=32, output_dims=4, activation=linear, in_dropout=0.1, out_dropout=0.0, bias=True, split_out=1)(132[p])\n",
      ")(1,188[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=ParallelAttnTCN°in-dims=2°te-dims=8°enc-emb=g32.g32.g32-r32.r32.r32°dec-emb=32-32(40,805[p])\u001b[0m\n",
      "\u001b[34mid: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/training/mdl=ParallelAttnTCN°in-dims=2°te-dims=8°enc-emb=g32.g32.g32-r32.r32.r32°dec-emb=32-32°ef-be=0.0001\n",
      "[wmse-wxentropy]\n",
      " - opt-parameters: 40,805[p] - device: cpu\n",
      " - save-mode: only_inf_metric (target_metric_crit: wxentropy)\n",
      " - counter_k: k(0/0) - counter_epoch: val_epoch(0/1)»earlystop_epoch(0/100)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 0/19600000 [11:01, ?it/s, id: 0 - epoch: 0/100,000(107/196)[wmse-wxentropy] b: 1,024 - __loss__: 76.26 (xentropy=73.75|mse=2.51) #7.001[segs]] \n",
      "\u001b[31m*** ctrl+c ***\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "End of training!!!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-2a033131b821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mki\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_train_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mmodel_train_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_val_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     '''\n",
      "\u001b[0;32m~/tesis/fuzzy-torch/fuzzytorch/handlers.py\u001b[0m in \u001b[0;36mfit_loader\u001b[0;34m(self, train_loader, val_loader, load, k_every, training_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m                         \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'[{lmonitor.name}] best_epoch: {lmonitor.get_best_epoch()}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                         \u001b[0mtxt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' - time_per_iteration: {lmonitor.get_time_per_iteration()}[segs]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                         \u001b[0mtxt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' - time_per_epoch: {lmonitor.get_time_per_epoch()/60.}[mins]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m                         \u001b[0mtxt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' - total_time: {lmonitor.get_total_time()/60.:3f}[mins]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tesis/fuzzy-torch/fuzzytorch/monitors.py\u001b[0m in \u001b[0;36mget_time_per_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_time_per_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_per_epoch_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_evaluation_set_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_total_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tesis/fuzzy-torch/fuzzytorch/monitors.py\u001b[0m in \u001b[0;36mget_evaluation_set_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_evaluation_set_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_df_epoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__set__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_time_per_epoch_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "  \n",
    "mp_grid = model_collections.pms[0]\n",
    "\n",
    "### IDS\n",
    "model_ids = range(0, 5)\n",
    "for ki,model_id in enumerate(model_ids): # IDS\n",
    "    ### GET MODEL\n",
    "    mdl_kwargs = mp_grid['mdl_kwargs']\n",
    "    for k_ in ['mdl_kwargs', 'dec_mdl_kwargs']:\n",
    "        mp_grid[k_]['input_dims'] = s_train_loader.dataset.get_output_dims()\n",
    "        mp_grid[k_]['te_features'] = s_train_loader.dataset.get_te_features_dims()\n",
    "        mp_grid[k_]['curvelength_max'] = s_train_dataset.get_max_len()\n",
    "        \n",
    "    model = mdl_kwargs['C'](**mp_grid)\n",
    "    \n",
    "    ### OPTIMIZER\n",
    "    import torch.optim as optims\n",
    "    from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "    pre_optimizer_kwargs = {\n",
    "        'opt_kwargs':{\n",
    "            'lr':1e-3,\n",
    "        },\n",
    "        'decay_kwargs':{\n",
    "            'lr':0.9,\n",
    "        }\n",
    "    }\n",
    "    pre_optimizer = LossOptimizer(model, optims.Adam, **pre_optimizer_kwargs)\n",
    "\n",
    "    ### MONITORS\n",
    "    from fuzzytools.prints import print_bar\n",
    "    from fuzzytorch.handlers import ModelTrainHandler\n",
    "    from fuzzytorch.monitors import LossMonitor\n",
    "    from fuzzytorch import C_\n",
    "    import math\n",
    "\n",
    "    monitor_config = {\n",
    "        'val_epoch_counter_duration':1, # every k epochs check\n",
    "        'earlystop_epoch_duration':100,\n",
    "        #'save_mode':C_.SM_NO_SAVE,\n",
    "        #'save_mode':C_.SM_ALL,\n",
    "        #'save_mode':C_.SM_ONLY_ALL,\n",
    "        'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "        #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "        #'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "    }\n",
    "    pre_loss_monitors = LossMonitor(pre_loss, pre_optimizer, pre_metrics, **monitor_config)\n",
    "    \n",
    "    ### TRAIN\n",
    "    mtrain_config = {\n",
    "        'id':model_id,\n",
    "        'epochs_max':1e5,\n",
    "        'save_rootdir':f'../save/training',\n",
    "        'extra_model_name_dict':{\n",
    "            #'ef-be':f'1e{math.log10(s_train_loader.dataset.effective_beta_eps)}',\n",
    "            'ef-be':s_train_loader.dataset.effective_beta_eps,\n",
    "        },\n",
    "        'uses_train_eval_loader_methods':True,\n",
    "    }\n",
    "    model_train_handler = ModelTrainHandler(model, pre_loss_monitors, **mtrain_config)\n",
    "    model_train_handler.build_gpu(gpu_index=None)\n",
    "    if ki==0:\n",
    "        print(model_train_handler)\n",
    "    model_train_handler.fit_loader(s_train_loader, r_val_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\u001b[33m> creating dir: ../save/train_plots/mdl=ParallelAttnTCN°in-dims=2°te-dims=8°enc-emb=g32.g32.g32-r32.r32.r32°dec-emb=32-32°ef-be=0.0001\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 1040x320 with 1 Axes>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x7f6ce0f037f0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch\n",
    "import fuzzytorch.plots\n",
    "import fuzzytorch.plots.training as ffplots\n",
    "\n",
    "### training plots\n",
    "plot_kwargs = {\n",
    "    'save_rootdir':f'../save/train_plots',\n",
    "}\n",
    "ffplots.plot_loss(model_train_handler, **plot_kwargs)\n",
    "#ffplots.plot_evaluation_loss(train_handler, **plot_kwargs)\n",
    "#ffplots.plot_evaluation_metrics(train_handler, **plot_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\u001b[34m> loading model: ../save/training/mdl=ParallelAttnTCN°in-dims=2°te-dims=8°enc-emb=g32.g32.g32-r32.r32.r32°dec-emb=32-32°ef-be=0.0001/id=0°epoch=83.tfes\u001b[0m\n",
      "\u001b[32m> saving: ../save/experiments/mdl=ParallelAttnTCN°in-dims=2°te-dims=8°enc-emb=g32.g32.g32-r32.r32.r32°dec-emb=32-32°ef-be=0.0001/exp_id=0°id=0°set=train+val.mcmc.png\u001b[0m\n",
      "\u001b[33m> creating dir: ../save/experiments/mdl=ParallelAttnTCN°in-dims=2°te-dims=8°enc-emb=g32.g32.g32-r32.r32.r32°dec-emb=32-32°ef-be=0.0001\u001b[0m\n",
      "\u001b[34m> loading model: ../save/training/mdl=ParallelAttnTCN°in-dims=2°te-dims=8°enc-emb=g32.g32.g32-r32.r32.r32°dec-emb=32-32°ef-be=0.0001/id=0°epoch=83.tfes\u001b[0m\n",
      "\u001b[32m> saving: ../save/experiments/mdl=ParallelAttnTCN°in-dims=2°te-dims=8°enc-emb=g32.g32.g32-r32.r32.r32°dec-emb=32-32°ef-be=0.0001/exp_id=0°id=0°set=val.png\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../save/experiments/mdl=ParallelAttnTCN°in-dims=2°te-dims=8°enc-emb=g32.g32.g32-r32.r32.r32°dec-emb=32-32°ef-be=0.0001/exp_id=0°id=0°set=val.png'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import lcclassifier.experiments.images as exp_img\n",
    "\n",
    "### perform the experiments\n",
    "exp_kwargs = {\n",
    "    'save_rootdir':f'../save/experiments',\n",
    "    'm':4,\n",
    "    'send_email':0,\n",
    "}\n",
    "exp_img.reconstructions(model_train_handler, s_train_loader, **exp_kwargs)\n",
    "exp_img.reconstructions(model_train_handler, r_val_loader, **exp_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import lcclassifier.experiments.performance as exp_perf\n",
    "\n",
    "### perform the experiments\n",
    "exp_kwargs = {\n",
    "    'save_rootdir':f'../save/experiments',\n",
    "    'target_is_onehot':False,\n",
    "    'send_email':0,\n",
    "}\n",
    "exp_perf.reconstruction_along_days(model_train_handler, r_val_loader, **exp_kwargs) # over real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\u001b[34m> loading model: ../save/training/mdl=ParallelAttnTCN°in-dims=2°te-dims=8°enc-emb=g32.g32.g32-r32.r32.r32°dec-emb=32-32°ef-be=0.0001/id=0°epoch=83.tfes\u001b[0m\n",
      "100%|██████████| 80/80 [01:41,  1.27s/it, day: 70.0000/70.0000metrics_dict: {'b-precision': 0.8383132039122704, 'b-recall': 0.8292565485362096, 'b-f1score': 0.832933423849431, 'b-accuracy': 82.92565485362096}metrics_cdict: {'precision': {'SLSN': 1.0, 'SNIa': 0.9336099585062241, 'SNIbc': 0.5625, 'allSNII': 0.8571428571428571, 'b-accuracy': {'SLSN': 100.0, 'SNIa': 95.33898305084746, 'SNIbc': 60.0, 'allSNII': 76.36363636363637}}, 'recall': {'SLSN': 1.0, 'SNIa': 0.9533898305084746, 'SNIbc': 0.6, 'allSNII': 0.7636363636363637, 'b-accuracy': {'SLSN': 100.0, 'SNIa': 95.33898305084746, 'SNIbc': 60.0, 'allSNII': 76.36363636363637}}, 'f1score': {'SLSN': 1.0, 'SNIa': 0.9433962264150942, 'SNIbc': 0.5806451612903225, 'allSNII': 0.8076923076923076, 'b-accuracy': {'SLSN': 100.0, 'SNIa': 95.33898305084746, 'SNIbc': 60.0, 'allSNII': 76.36363636363637}}, 'true_samples': {'SLSN': 3, 'SNIa': 236, 'SNIbc': 15, 'allSNII': 55, 'b-accuracy': {'SLSN': 100.0, 'SNIa': 95.33898305084746, 'SNIbc': 60.0, 'allSNII': 76.36363636363637}}}]                                                                                                                                                                                            \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-2d66320a63fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m'send_email'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mexp_perf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_along_days\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_train_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_val_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mexp_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# over real\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tesis/sne-lightcurves-classifier/lcclassifier/experiments/performance.py\u001b[0m in \u001b[0;36mmetrics_along_days\u001b[0;34m(train_handler, data_loader, target_is_onehot, figsize, save_rootdir, save_fext, days_N, eps, send_email, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m                         \u001b[0;34m'time_per_iteration'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_per_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0;31m#'time_per_epoch_set':{set_name:lmonitor.get_time_per_epoch_set(set_name) for set_name in set_names},\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                         \u001b[0;34m'time_per_epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_per_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m                         \u001b[0;34m'total_time'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_total_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \t\t}\n",
      "\u001b[0;32m~/tesis/fuzzy-torch/fuzzytorch/monitors.py\u001b[0m in \u001b[0;36mget_time_per_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_time_per_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_per_epoch_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_evaluation_set_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_total_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tesis/fuzzy-torch/fuzzytorch/monitors.py\u001b[0m in \u001b[0;36mget_evaluation_set_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_evaluation_set_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_df_epoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__set__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_time_per_epoch_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import lcclassifier.experiments.performance as exp_perf\n",
    "\n",
    "### perform the experiments\n",
    "exp_kwargs = {\n",
    "    'save_rootdir':f'../save/experiments',\n",
    "    'target_is_onehot':False,\n",
    "    'send_email':0,\n",
    "}\n",
    "exp_perf.metrics_along_days(model_train_handler, r_val_loader, **exp_kwargs) # over real"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
