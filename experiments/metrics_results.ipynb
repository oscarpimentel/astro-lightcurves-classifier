{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../fuzzy-torch') # or just install the module\n",
    "sys.path.append('../../fuzzy-tools') # or just install the module\n",
    "sys.path.append('../../astro-lightcurves-handler') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mdl=ParallelTimeModRNN~input_dims=1~dummy_seft=1~enc_emb=g64-g64.r64-r64~dec_emb=g1-g128.r1-r128~cell=GRU~b=202~pb=.~bypass_synth=0~bypass_prob=0.0~ds_prob=0.1',\n",
       " 'mdl=ParallelTimeModRNN~input_dims=1~dummy_seft=1~enc_emb=g64-g64.r64-r64~dec_emb=g1-g128.r1-r128~cell=LSTM~b=202~pb=.~bypass_synth=0~bypass_prob=0.0~ds_prob=0.1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lcclassifier.results.utils import get_model_names\n",
    "\n",
    "rootdir = '../save'\n",
    "set_name = 'test'\n",
    "method = 'spm-mcmc-estw'\n",
    "cfilename = f'survey=alerceZTFv7.1~bands=gr~mode=onlySNe~method={method}'\n",
    "kf = '.'\n",
    "\n",
    "model_names = get_model_names(rootdir, cfilename, kf, set_name)\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from lcclassifier.results.performance import plot_metric\n",
    "\n",
    "metric_names = [\n",
    "    #'precision',\n",
    "    #'recall',\n",
    "    #'f1score',\n",
    "    'aucroc',\n",
    "    #'aucpr',\n",
    "    ]\n",
    "\n",
    "bypass_prob = 0.0\n",
    "ds_prob = 0.1\n",
    "new_model_names = []\n",
    "for model_name in model_names:\n",
    "    if not 'pb=.' in model_name:\n",
    "        continue\n",
    "    if f'bypass_synth=0~bypass_prob={bypass_prob}~ds_prob={ds_prob}' in model_name:\n",
    "        new_model_names += [model_name]\n",
    "plot_metric(rootdir, cfilename, kf, set_name, new_model_names, metric_names,\n",
    "    std_prop=1/2,\n",
    "    #target_class='SNIa', # SLSN SNIbc SNIIbn SNIa\n",
    "    #baseline_rootdir=None,\n",
    "    #dict_name='thdays_class_metrics_all_bands',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lcclassifier.results.cm import plot_cm\n",
    "\n",
    "new_model_names = []\n",
    "for model_name in model_names:\n",
    "    if not 'b=202' in model_name:\n",
    "        #continue\n",
    "        pass\n",
    "    if 'RNN' in model_name:\n",
    "        continue\n",
    "        pass\n",
    "    if 'Attn' in model_name:\n",
    "        #continue\n",
    "        pass\n",
    "    new_model_names += [model_name]\n",
    "plot_cm(rootdir, cfilename, kf, set_name, new_model_names,\n",
    "    #export_animation=True,\n",
    "    #dict_name='thdays_class_metrics_all_bands',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opimentel/anaconda3/envs/lchandler/lib/python3.7/site-packages/numpy/lib/function_base.py:3968: RuntimeWarning: invalid value encountered in multiply\n",
      "  x2 = take(ap, indices_above, axis=axis) * weights_above\n",
      "/home/opimentel/anaconda3/envs/lchandler/lib/python3.7/site-packages/numpy/core/_methods.py:202: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opimentel/anaconda3/envs/lchandler/lib/python3.7/site-packages/numpy/core/_methods.py:202: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "/home/opimentel/anaconda3/envs/lchandler/lib/python3.7/site-packages/numpy/core/_methods.py:202: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b-Precision${}_{ }^{\\ddag}$</th>\n",
       "      <th>b-Recall${}_{ }^{\\ddag}$</th>\n",
       "      <th>b-$F_1$score${}_{ }^{\\ddag}$</th>\n",
       "      <th>b-AUCROC${}_{ }^{\\ddag}$</th>\n",
       "      <th>b-AUCPR${}_{ }^{\\ddag}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model=BRF (fmode***all; training-set***[r])</th>\n",
       "      <td>-inf±─</td>\n",
       "      <td>-inf±─</td>\n",
       "      <td>-inf±─</td>\n",
       "      <td>-inf±─</td>\n",
       "      <td>-inf±─</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model=P-TimeModRNN+$\\Delta t$ (cell***GRU)</th>\n",
       "      <td>.509±.026</td>\n",
       "      <td>.597±.035</td>\n",
       "      <td>.490±.029</td>\n",
       "      <td>.810±.021</td>\n",
       "      <td>.550±.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model=P-TimeModRNN+$\\Delta t$ (cell***LSTM)</th>\n",
       "      <td>.513±.021</td>\n",
       "      <td>.601±.033</td>\n",
       "      <td>.490±.025</td>\n",
       "      <td>.814±.022</td>\n",
       "      <td>.550±.043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            b-Precision${}_{ }^{\\ddag}$  \\\n",
       "Model=BRF (fmode***all; training-set***[r])                      -inf±─   \n",
       "Model=P-TimeModRNN+$\\Delta t$ (cell***GRU)                    .509±.026   \n",
       "Model=P-TimeModRNN+$\\Delta t$ (cell***LSTM)                   .513±.021   \n",
       "\n",
       "                                            b-Recall${}_{ }^{\\ddag}$  \\\n",
       "Model=BRF (fmode***all; training-set***[r])                   -inf±─   \n",
       "Model=P-TimeModRNN+$\\Delta t$ (cell***GRU)                 .597±.035   \n",
       "Model=P-TimeModRNN+$\\Delta t$ (cell***LSTM)                .601±.033   \n",
       "\n",
       "                                            b-$F_1$score${}_{ }^{\\ddag}$  \\\n",
       "Model=BRF (fmode***all; training-set***[r])                       -inf±─   \n",
       "Model=P-TimeModRNN+$\\Delta t$ (cell***GRU)                     .490±.029   \n",
       "Model=P-TimeModRNN+$\\Delta t$ (cell***LSTM)                    .490±.025   \n",
       "\n",
       "                                            b-AUCROC${}_{ }^{\\ddag}$  \\\n",
       "Model=BRF (fmode***all; training-set***[r])                   -inf±─   \n",
       "Model=P-TimeModRNN+$\\Delta t$ (cell***GRU)                 .810±.021   \n",
       "Model=P-TimeModRNN+$\\Delta t$ (cell***LSTM)                .814±.022   \n",
       "\n",
       "                                            b-AUCPR${}_{ }^{\\ddag}$  \n",
       "Model=BRF (fmode***all; training-set***[r])                  -inf±─  \n",
       "Model=P-TimeModRNN+$\\Delta t$ (cell***GRU)                .550±.047  \n",
       "Model=P-TimeModRNN+$\\Delta t$ (cell***LSTM)               .550±.043  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m%vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "\\def\\tabsrule{\\rule{0pt}{10pt}\\rule[0pt]{0pt}{0pt}}\n",
      "\\def\\tabbline{\\Xcline{1-6}{1.5pt}\\tabsrule}\n",
      "\\begin{table*}[!t]\n",
      "\\centering\n",
      "\\caption{\n",
      "?\n",
      "}\n",
      "\\label{tab:?}\\vspace{.1cm}\n",
      "\\tiny\\scriptsize\\footnotesize\\small\\normalsize\n",
      "\\normalsize\n",
      "\\begin{tabular}{lccccc}\n",
      "\\tabbline\n",
      "Model & b-Precision${}_{ }^{\\ddag}$ & b-Recall${}_{ }^{\\ddag}$ & b-$F_1$score${}_{ }^{\\ddag}$ & b-AUCROC${}_{ }^{\\ddag}$ & b-AUCPR${}_{ }^{\\ddag}$ \\tabsrule\\\\\n",
      "\\cmidrule{1-1}\\cmidrule{2-6}\n",
      "BRF (fmode=all; training-set=[r]) & -inf$\\pm$-- & -inf$\\pm$-- & -inf$\\pm$-- & -inf$\\pm$-- & -inf$\\pm$--  \\tabsrule\\\\\n",
      "P-TimeModRNN+$\\Delta t$ (cell=GRU) & .509$\\pm$.026 & .597$\\pm$.035 & .490$\\pm$.029 & .810$\\pm$.021 & .550$\\pm$.047  \\tabsrule\\\\\n",
      "P-TimeModRNN+$\\Delta t$ (cell=LSTM) & .513$\\pm$.021 & .601$\\pm$.033 & .490$\\pm$.025 & .814$\\pm$.022 & .550$\\pm$.043  \\tabsrule\\\\\n",
      "\\tabbline\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "%^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lcclassifier.results.tables import get_ps_performance_df\n",
    "from fuzzytools.latex.latex_tables import LatexTable\n",
    "\n",
    "metric_names = [\n",
    "    'precision',\n",
    "    'recall',\n",
    "    'f1score',\n",
    "    'aucroc',\n",
    "    'aucpr',\n",
    "    ]\n",
    "\n",
    "bypass_prob = 0.0\n",
    "ds_prob = 0.1\n",
    "new_model_names = []\n",
    "for model_name in model_names:\n",
    "    if not 'pb=.' in model_name:\n",
    "        continue\n",
    "    if f'bypass_synth=0~bypass_prob={bypass_prob}~ds_prob={ds_prob}' in model_name:\n",
    "        new_model_names += [model_name]\n",
    "info_df = get_ps_performance_df(rootdir, cfilename, kf, set_name, new_model_names, metric_names,\n",
    "    #uses_avg=True,\n",
    "    #dict_name='thdays_class_metrics_all_bands',\n",
    "    #target_class='SNIa', # SNIa\n",
    "    #'override_model_name':False, # False True\n",
    "    #baseline_rootdir=None,\n",
    "    )\n",
    "for k in range(0, len(info_df)):\n",
    "    info_df.indexs[k] = info_df.indexs[k].replace('=', '***')\n",
    "    info_df.indexs[k] = info_df.indexs[k].replace('Model***', 'Model=')\n",
    "display(info_df())\n",
    "\n",
    "latex_table = LatexTable(info_df(),\n",
    "    centered=True,\n",
    "    repr_replace_dict={\n",
    "        '***':'=',\n",
    "        '-999.000±.000':'--',\n",
    "        },\n",
    "    )\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fuzzytools.datascience import statistical_tests as statistical_tests\n",
    "from lcclassifier import _C\n",
    "\n",
    "def get_dict(info_df, metric_name, str_to_ignore, ds_prob):\n",
    "    df = info_df.get_df()\n",
    "    df = df[[c for c in df.columns if _C.METRICS_D[metric_name]['mn'] in c]]\n",
    "    values_dict = df.to_dict()\n",
    "    values_dict = values_dict[list(values_dict.keys())[0]]\n",
    "    new_values_dict = {}\n",
    "    for k in values_dict.keys():\n",
    "        if 'BRF' in k:\n",
    "            new_values_dict[k] = values_dict[k]\n",
    "        else:\n",
    "            if str_to_ignore in k:\n",
    "                continue\n",
    "            if f'bypass_synth***1' in k:\n",
    "                continue\n",
    "            if f'ds_prob***{ds_prob}' in k:\n",
    "                new_values_dict[k] = values_dict[k]\n",
    "            \n",
    "    return new_values_dict\n",
    "\n",
    "metric_names = [\n",
    "    'precision',\n",
    "    'recall',\n",
    "    'f1score',\n",
    "    'aucroc',\n",
    "    'aucpr',\n",
    "    ]\n",
    "ds_prob = 0.0\n",
    "for str_to_ignore in ['Models=P', 'Models=S']:\n",
    "#ds_prob = 0.1\n",
    "#for str_to_ignore in ['RNN']:\n",
    "    for metric_name in metric_names:\n",
    "        print(f'str_to_ignore={str_to_ignore}; metric_name={metric_name}; ds_prob={ds_prob}')\n",
    "        values_dict = get_dict(info_df, metric_name, str_to_ignore, ds_prob)\n",
    "        test = statistical_tests.permutationtest # ttest welchtest permutationtest\n",
    "        df = statistical_tests.gridtest_greater(values_dict, test,\n",
    "            test_kwargs={'num_rounds':1e5}, # 1e4 1e5\n",
    "            th_pvalue_txt=0,\n",
    "            n_decimals=4,\n",
    "            check_samples=False,\n",
    "            )\n",
    "        display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
