{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../fuzzy-torch')  # or just install the module\n",
    "sys.path.append('../fuzzy-tools')  # or just install the module\n",
    "sys.path.append('../astro-lightcurves-handler')  # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lcclassifier.results.utils import get_model_names\n",
    "\n",
    "rootdir = 'save/paper_v3'\n",
    "set_name = 'test'\n",
    "method = 'spm-mcmc-estw'\n",
    "cfilename = f'survey=alerceZTFv7.1~bands=gr~mode=onlySNe~method={method}'\n",
    "kf = '.'\n",
    "\n",
    "model_names = get_model_names(rootdir, cfilename, kf, set_name)\n",
    "print(f'model_names (#{len(model_names)}):')\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "print('/'*100)\n",
    "bypass_prob = 0.0\n",
    "ds_prob = 0.1\n",
    "new_model_names = []\n",
    "for model_name in model_names:\n",
    "    if not 'pb=.' in model_name:\n",
    "        continue\n",
    "    if f'bypass_synth=0~bypass_prob={bypass_prob}~ds_prob={ds_prob}' in model_name:\n",
    "        new_model_names += [model_name]\n",
    "for model_name in new_model_names:\n",
    "    print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from lcclassifier.results.performances import plot_metric\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "def interact_f(dict_name, metric_name, target_class):\n",
    "    plot_metric(rootdir, cfilename, kf, set_name, new_model_names, metric_name,\n",
    "        std_prop=1 / 2,\n",
    "        target_class=target_class,\n",
    "        dict_name=dict_name,\n",
    "        )\n",
    "widgets.interact(interact_f,\n",
    "    dict_name=['thdays_class_metrics', 'thdays_class_metrics_all_bands'],\n",
    "    metric_name=['aucroc', 'precision', 'recall', 'f1score', 'aucpr'],\n",
    "    target_class=[None, ' SNIbc', 'SNIIbn', 'SNIa', 'SLSN'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lcclassifier.results.cms import plot_cm\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "def interact_f(dict_name, export_animation, alphabet_count_offset):\n",
    "    new_model_names = []\n",
    "    for model_name in model_names:\n",
    "        if not 'b=202' in model_name:\n",
    "            #continue\n",
    "            pass\n",
    "        if 'RNN' in model_name:\n",
    "            continue\n",
    "            pass\n",
    "        if 'Attn' in model_name:\n",
    "            #continue\n",
    "            pass\n",
    "        new_model_names += [model_name]\n",
    "    plot_cm(rootdir, cfilename, kf, set_name, new_model_names,\n",
    "        export_animation=export_animation,\n",
    "        dict_name=dict_name,\n",
    "        alphabet_count_offset=alphabet_count_offset,\n",
    "        )\n",
    "widgets.interact(interact_f,\n",
    "    dict_name=['thdays_class_metrics', 'thdays_class_metrics_all_bands'],\n",
    "    export_animation=False,\n",
    "    alphabet_count_offset=[1, 0],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lcclassifier.results.tables import get_ps_performance_df\n",
    "from fuzzytools.latex.latex_tables import LatexTable\n",
    "import ipywidgets as widgets\n",
    "\n",
    "metric_names = [\n",
    "    'precision',\n",
    "    'recall',\n",
    "    'f1score',\n",
    "    'aucroc',\n",
    "    'aucpr',\n",
    "    ]\n",
    "\n",
    "def interact_f(uses_avg, dict_name, target_class):\n",
    "    bypass_prob = 0.0\n",
    "    ds_prob = 0.1\n",
    "    new_model_names = []\n",
    "    for model_name in model_names:\n",
    "        if not 'pb=.' in model_name:\n",
    "            continue\n",
    "        if f'bypass_synth=0~bypass_prob={bypass_prob}~ds_prob={ds_prob}' in model_name:\n",
    "            new_model_names += [model_name]\n",
    "    info_df = get_ps_performance_df(rootdir, cfilename, kf, set_name, new_model_names, metric_names,\n",
    "        uses_avg=uses_avg,\n",
    "        dict_name=dict_name,\n",
    "        target_class=target_class,\n",
    "        #'override_model_name':False, # False True\n",
    "        )\n",
    "    for k in range(0, len(info_df)):\n",
    "        info_df.indexs[k] = info_df.indexs[k].replace('=', '***')\n",
    "        info_df.indexs[k] = info_df.indexs[k].replace('Model***', 'Model=')\n",
    "    display(info_df())\n",
    "\n",
    "    latex_table = LatexTable(info_df(),\n",
    "        centered=True,\n",
    "        repr_replace_dict={\n",
    "            '***':'=',\n",
    "            '-999.000Â±.000':'--',\n",
    "            },\n",
    "        )\n",
    "    print(latex_table)\n",
    "\n",
    "widgets.interact(interact_f,\n",
    "    uses_avg=False,\n",
    "    dict_name=['thdays_class_metrics', 'thdays_class_metrics_all_bands'],\n",
    "    target_class=[None, ' SNIbc', 'SNIIbn', 'SNIa', 'SLSN'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fuzzytools.datascience import statistical_tests as statistical_tests\n",
    "from lcclassifier import _C\n",
    "\n",
    "def get_dict(info_df, metric_name, str_to_ignore, ds_prob):\n",
    "    df = info_df.get_df()\n",
    "    df = df[[c for c in df.columns if _C.METRICS_D[metric_name]['mn'] in c]]\n",
    "    values_dict = df.to_dict()\n",
    "    values_dict = values_dict[list(values_dict.keys())[0]]\n",
    "    new_values_dict = {}\n",
    "    for k in values_dict.keys():\n",
    "        if 'BRF' in k:\n",
    "            new_values_dict[k] = values_dict[k]\n",
    "        else:\n",
    "            if str_to_ignore in k:\n",
    "                continue\n",
    "            if f'bypass_synth***1' in k:\n",
    "                continue\n",
    "            if f'ds_prob***{ds_prob}' in k:\n",
    "                new_values_dict[k] = values_dict[k]\n",
    "            \n",
    "    return new_values_dict\n",
    "\n",
    "metric_names = [\n",
    "    'precision',\n",
    "    'recall',\n",
    "    'f1score',\n",
    "    'aucroc',\n",
    "    'aucpr',\n",
    "    ]\n",
    "ds_prob = 0.0\n",
    "for str_to_ignore in ['Models=P', 'Models=S']:\n",
    "#ds_prob = 0.1\n",
    "#for str_to_ignore in ['RNN']:\n",
    "    for metric_name in metric_names:\n",
    "        print(f'str_to_ignore={str_to_ignore}; metric_name={metric_name}; ds_prob={ds_prob}')\n",
    "        values_dict = get_dict(info_df, metric_name, str_to_ignore, ds_prob)\n",
    "        test = statistical_tests.permutationtest # ttest welchtest permutationtest\n",
    "        df = statistical_tests.gridtest_greater(values_dict, test,\n",
    "            test_kwargs={'num_rounds':1e5}, # 1e4 1e5\n",
    "            th_pvalue_txt=0,\n",
    "            n_decimals=4,\n",
    "            check_samples=False,\n",
    "            )\n",
    "        display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
